{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"eMYRMpXopPR4","papermill":{"duration":0.008314,"end_time":"2021-04-06T15:44:59.684598","exception":false,"start_time":"2021-04-06T15:44:59.676284","status":"completed"},"tags":[]},"source":["This notebook is a fork of https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-04-06T15:44:59.704759Z","iopub.status.busy":"2021-04-06T15:44:59.704233Z","iopub.status.idle":"2021-04-06T15:45:00.639211Z","shell.execute_reply":"2021-04-06T15:45:00.638701Z"},"id":"9lUq6aN2pPR9","papermill":{"duration":0.947332,"end_time":"2021-04-06T15:45:00.639328","exception":false,"start_time":"2021-04-06T15:44:59.691996","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np, pandas as pd\n","from glob import glob\n","import shutil, os\n","from PIL import Image\n","import seaborn as sns, gc\n","from yolov5.utils.general import scale_boxes, xyxy2xywh"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["SUBM_FOLDER = 'images/'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-04-06T15:45:00.658858Z","iopub.status.busy":"2021-04-06T15:45:00.658102Z","iopub.status.idle":"2021-04-06T15:45:00.662122Z","shell.execute_reply":"2021-04-06T15:45:00.661594Z"},"id":"NFACkGfTpPR_","papermill":{"duration":0.014754,"end_time":"2021-04-06T15:45:00.662251","exception":false,"start_time":"2021-04-06T15:45:00.647497","status":"completed"},"tags":[]},"outputs":[],"source":["test_img = SUBM_FOLDER + 'test.png'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["global classes\n","classes = ['Aortic enlargement',\n","            'Atelectasis',\n","            'Calcification',\n","            'Cardiomegaly',\n","            'Consolidation',\n","            'ILD',\n","            'Infiltration',\n","            'Lung Opacity',\n","            'Nodule/Mass',\n","            'Other lesion',\n","            'Pleural effusion',\n","            'Pleural thickening',\n","            'Pneumothorax',\n","            'Pulmonary fibrosis']"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aq2HBU6-pPSC","papermill":{"duration":0.007755,"end_time":"2021-04-06T15:45:00.743372","exception":false,"start_time":"2021-04-06T15:45:00.735617","status":"completed"},"tags":[]},"source":["# YOLOv5 Stuff"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-04-06T15:45:00.765003Z","iopub.status.busy":"2021-04-06T15:45:00.764509Z","iopub.status.idle":"2021-04-06T15:45:03.638672Z","shell.execute_reply":"2021-04-06T15:45:03.638242Z"},"executionInfo":{"elapsed":3995,"status":"ok","timestamp":1684855529981,"user":{"displayName":"ƒê·∫°i-Nghƒ©a Nguy·ªÖn","userId":"07632132049877661893"},"user_tz":-420},"id":"pzMkXWgjpPSC","outputId":"9ea9fdde-8904-4704-e264-589d84f79c72","papermill":{"duration":2.887404,"end_time":"2021-04-06T15:45:03.638769","exception":false,"start_time":"2021-04-06T15:45:00.751365","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Setup complete. Using torch 1.7.0 _CudaDeviceProperties(name='NVIDIA GeForce GTX TITAN X', major=5, minor=2, total_memory=12204MB, multi_processor_count=24)\n"]}],"source":["#shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\n","#os.chdir('/content/drive/MyDrive/Thesis/yolov5')\n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","\n","clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["import cv2\n","import colorsys\n","import random\n","\n","colors = [\n","    (33, 33, 33), #Dark Gray\n","    (47, 79, 79), #Dark Slate Gray\n","    (25, 25, 112), #Midnight Blue\n","    (0, 0, 128), #Navy Blue\n","    (139, 0, 0), #Dark Red\n","    (128, 0, 0), #Maroon\n","    (128, 0, 128), #Indigo\n","    (139, 0, 139), #Dark Magenta\n","    (128, 128, 0), #Olive\n","    (0, 128, 0), #Dark Green\n","    (0, 128, 128), #Teal\n","    (47, 79, 79), #Dark Slate Gray\n","    (139, 69, 19), #Saddle Brown\n","    (0, 100, 0), #Dark Green\n","]\n","\n","def visualize_yolo(image_path, preds, width, height):\n","    print(\"Draw boxes!\")\n","    global classes, colors\n","    image = cv2.imread(image_path)\n","\n","    if len(preds) == 0:\n","        return image\n","    \n","    if preds[0][0] == 14:\n","        return image\n","    \n","    for pred in preds:\n","        label, score, box = pred\n","        color = colors[int(label)]\n","        label = classes[int(label)]\n","\n","        # Generate a random color based on the label\n","        #hsv = [(hash(label) % 255) / 255.0, 1.0, 1.0]\n","        #color = tuple(int(255 * c) for c in colorsys.hsv_to_rgb(*hsv))\n","        # Extract box coordinates\n","        x_min, y_min, x_max, y_max = map(int, box)\n","\n","        # Draw the bounding box on the image\n","        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n","\n","        # Create the label string\n","        #label_text = f\"{label}: {score:.2f}\"\n","        label_text = f\"{label}\"\n","\n","        # Get the size of the label text\n","        font_scale = height / 500 * 0.5\n","        label_size, _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 1)\n","\n","        # Draw the label rectangle\n","        cv2.rectangle(image, (x_min, y_min - label_size[1] - 5),\n","                      (x_min + label_size[0], y_min - 0), color, cv2.FILLED)\n","\n","        # Put the label text\n","        cv2.putText(image, label_text, (x_min, y_min - 2),\n","                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 1)\n","    \n","    # cv2.imshow(\"Bounding Boxes\", image)\n","    # cv2.waitKey(0)\n","    # cv2.destroyAllWindows()\n","    return image\n","    # Display the image with bounding boxes\n","    # cv2.imshow(\"Bounding Boxes\", image)\n","    # cv2.waitKey(0)\n","    # cv2.destroyAllWindows()\n","        "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UWUjF-sRpPSD","papermill":{"duration":0.008243,"end_time":"2021-04-06T15:45:03.656264","exception":false,"start_time":"2021-04-06T15:45:03.648021","status":"completed"},"tags":[]},"source":["# Inference"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-04-06T15:45:03.682147Z","iopub.status.busy":"2021-04-06T15:45:03.680955Z","iopub.status.idle":"2021-04-06T15:45:03.683395Z","shell.execute_reply":"2021-04-06T15:45:03.683822Z"},"id":"qkrwkn_UpPSD","papermill":{"duration":0.019291,"end_time":"2021-04-06T15:45:03.683919","exception":false,"start_time":"2021-04-06T15:45:03.664628","status":"completed"},"tags":[]},"outputs":[],"source":["def yolo2voc(image_height, image_width, bboxes):\n","    \"\"\"\n","    yolo => [xmid, ymid, w, h] (normalized)\n","    voc  => [x1, y1, x2, y1]\n","    \n","    \"\"\" \n","    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n","    \n","    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n","    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n","    \n","    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n","    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n","    \n","    return bboxes"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["YOLOv5 üöÄ v7.0-175-g5f11555 Python-3.7.16 torch-1.7.0 CUDA:0 (NVIDIA GeForce GTX TITAN X, 12204MiB)\n","\n","Fusing layers... \n","Model summary: 322 layers, 86260891 parameters, 0 gradients, 204.0 GFLOPs\n","Adding AutoShape... \n","YOLOv5 üöÄ v7.0-175-g5f11555 Python-3.7.16 torch-1.7.0 CUDA:0 (NVIDIA GeForce GTX TITAN X, 12204MiB)\n","\n","Fusing layers... \n","Model summary: 322 layers, 86260891 parameters, 0 gradients, 204.0 GFLOPs\n","Adding AutoShape... \n","YOLOv5 üöÄ v7.0-175-g5f11555 Python-3.7.16 torch-1.7.0 CUDA:0 (NVIDIA GeForce GTX TITAN X, 12204MiB)\n","\n","Fusing layers... \n","Model summary: 322 layers, 86260891 parameters, 0 gradients, 204.0 GFLOPs\n","Adding AutoShape... \n","YOLOv5 üöÄ v7.0-175-g5f11555 Python-3.7.16 torch-1.7.0 CUDA:0 (NVIDIA GeForce GTX TITAN X, 12204MiB)\n","\n","Fusing layers... \n","Model summary: 322 layers, 86260891 parameters, 0 gradients, 204.0 GFLOPs\n","Adding AutoShape... \n","YOLOv5 üöÄ v7.0-175-g5f11555 Python-3.7.16 torch-1.7.0 CUDA:0 (NVIDIA GeForce GTX TITAN X, 12204MiB)\n","\n","Fusing layers... \n","Model summary: 322 layers, 86260891 parameters, 0 gradients, 204.0 GFLOPs\n","Adding AutoShape... \n"]}],"source":["models = []\n","for i in range(0,5):\n","    models.append(torch.hub.load('./yolov5', 'custom', path=f'weights/best_{i}.pt', source='local'))\n","    models[i].iou = 0.25\n","    models[i].conf = 0.01\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from PIL import Image\n","def detect_img(model, img, size = 640):\n","        results = model(img, size)\n","\n","        image = Image.open(img)\n","        width, height = image.size\n","\n","        dets = []\n","        for i, detect_info in enumerate(results.xyxy):\n","                img1shape = (height, width)\n","                detected_coordinates = detect_info[:, :4]\n","                img0shape = (height, width)\n","                detect_info[:, :4] = scale_boxes(img1shape, detected_coordinates, img0shape).round()\n","                xywhs = xyxy2xywh(detect_info[:, 0:4]).cpu().numpy()\n","                confs = detect_info[:, 4].cpu().numpy()\n","                clss = detect_info[:, 5].cpu().numpy()\n","                for i in reversed(list(range(0, len(clss)))):\n","                        tmp = [clss[i], xywhs[i][0] / width, xywhs[i][1] / height, xywhs[i][2] / width, xywhs[i][3] / height, confs[i]]\n","                        for num in tmp:\n","                                dets.append(round(num, 6))\n","        return dets"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def run_yolo_5fold(test_img, width, height):\n","    print('Yolo 5 fold running!')\n","    preds = []\n","    for i in range(0,5):\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","        PredictionStrings = ''\n","\n","        w, h = width, height\n","\n","        dets = detect_img(models[i], test_img, 640)\n","\n","        data = np.array(dets).astype(np.float32).reshape(-1, 6)\n","        data = data[:, [0, 5, 1, 2, 3, 4]]\n","        bboxes = list(np.concatenate((data[:, :2], yolo2voc(h, w, data[:, 2:])), axis =1).reshape(-1).astype(str))\n","        for idx in range(len(bboxes)):\n","            bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n","        PredictionStrings = ' '.join(bboxes)\n","        preds.append(PredictionStrings)\n","    return preds\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Ensemble all Yolo Folds"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from ensemble_boxes import weighted_boxes_fusion\n","import pandas as pd\n","\n","\n","SUBM_PATH = './subm_folder/'\n","\n","def ensemble(\n","    preds,\n","    weights,\n","    iou_same=0.5,\n","    skip_box_thr=0.00000001,\n","    w = 640,\n","    h = 640\n","):\n","    print(\"Ensemble 5 folds!\")\n","\n","    boxes_list = []\n","    scores_list = []\n","    labels_list = []\n","    empty = True\n","    for i in range(len(preds)):\n","        boxes = []\n","        scores = []\n","        labels = []\n","        p1 = preds[i]\n","        if str(p1) != 'nan':\n","            arr = p1.strip().split(' ')\n","            for k in range(0, len(arr), 6):\n","                cls = int(arr[k])\n","                prob = float(arr[k + 1])\n","                x1 = float(arr[k + 2]) / w\n","                y1 = float(arr[k + 3]) / h\n","                x2 = float(arr[k + 4]) / w\n","                y2 = float(arr[k + 5]) / h\n","                boxes.append([x1, y1, x2, y2])\n","                scores.append(prob)\n","                labels.append(cls)\n","\n","        boxes_list.append(boxes)\n","        scores_list.append(scores)\n","        labels_list.append(labels)\n","\n","    boxes, scores, labels = weighted_boxes_fusion(\n","        boxes_list,\n","        scores_list,\n","        labels_list,\n","        iou_thr=iou_same,\n","        skip_box_thr=skip_box_thr,\n","        weights=weights,\n","        allows_overflow=True\n","    )\n","    boxes = boxes.tolist()\n","    scores = scores.tolist()\n","    labels = labels.tolist()\n","    \n","    # print(len(boxes), len(labels), len(scores))\n","    if len(boxes) == 0:\n","        boxes.append([0, 0, 1, 1])\n","        scores.append(1)\n","        labels.append(14)\n","\n","    return boxes, scores, labels"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["### 2 CLASS FILTER"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from dataclasses import dataclass, field\n","from typing import Dict, Any, Tuple, Union, List\n","\n","\n","@dataclass\n","class Flags:\n","    # General\n","    debug: bool = True\n","    outdir: str = \"results/det\"\n","    device: str = \"cuda:0\"\n","\n","    # Data config\n","    imgdir_name: str = \"vinbigdata-chest-xray-resized-png-256x256\"\n","    # split_mode: str = \"all_train\"  # all_train or valid20\n","    seed: int = 111\n","    target_fold: int = 0  # 0~4\n","    label_smoothing: float = 0.0\n","    # Model config\n","    model_name: str = \"resnet18\"\n","    model_mode: str = \"normal\"  # normal, cnn_fixed supported\n","    # Training config\n","    epoch: int = 20\n","    batchsize: int = 8\n","    valid_batchsize: int = 16\n","    num_workers: int = 4\n","    snapshot_freq: int = 5\n","    ema_decay: float = 0.999  # negative value is to inactivate ema.\n","    scheduler_type: str = \"\"\n","    scheduler_kwargs: Dict[str, Any] = field(default_factory=lambda: {})\n","    scheduler_trigger: List[Union[int, str]] = field(default_factory=lambda: [1, \"iteration\"])\n","    aug_kwargs: Dict[str, Dict[str, Any]] = field(default_factory=lambda: {})\n","    mixup_prob: float = -1.0  # Apply mixup augmentation when positive value is set.\n","\n","    def update(self, param_dict: Dict) -> \"Flags\":\n","        # Overwrite by `param_dict`\n","        for key, value in param_dict.items():\n","            if not hasattr(self, key):\n","                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n","            setattr(self, key, value)\n","        return self"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#!pip install pytorch-pfn-extras==0.3.2\n","#!pip install timm==0.3.4"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["flags = Flags()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from torch import nn\n","from torch.nn import Linear\n","from torch.utils.data.dataloader import DataLoader"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\n","class CNNFixedPredictor(nn.Module):\n","    def __init__(self, cnn: nn.Module, num_classes: int = 2):\n","        super(CNNFixedPredictor, self).__init__()\n","        self.cnn = cnn\n","        self.lin = Linear(cnn.num_features, num_classes)\n","        print(\"cnn.num_features\", cnn.num_features)\n","\n","        # We do not learn CNN parameters.\n","        # https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n","        for param in self.cnn.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, x):\n","        feat = self.cnn(x)\n","        return self.lin(feat)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import timm\n","\n","\n","def build_predictor(model_name: str, model_mode: str = \"normal\"):\n","    if model_mode == \"normal\":\n","        # normal configuration. train all parameters.\n","        return timm.create_model(model_name, pretrained=True, num_classes=2, in_chans=3)\n","    elif model_mode == \"cnn_fixed\":\n","        # normal configuration. train all parameters.\n","        # https://rwightman.github.io/pytorch-image-models/feature_extraction/\n","        timm_model = timm.create_model(model_name, pretrained=True, num_classes=0, in_chans=3)\n","        return CNNFixedPredictor(timm_model, num_classes=2)\n","    else:\n","        raise ValueError(f\"[ERROR] Unexpected value model_mode={model_mode}\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","\n","def cross_entropy_with_logits(input, target, dim=-1):\n","    loss = torch.sum(- target * F.log_softmax(input, dim), dim)\n","    return loss.mean()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["fail to import apex_C: apex was not installed or installed without --cpp_ext.\n","fail to import amp_C: apex was not installed or installed without --cpp_ext.\n"]},{"name":"stdout","output_type":"stream","text":["1.7.0\n"]}],"source":["import torch\n","print(torch.__version__)\n","import torch.nn.functional as F\n","from torch import nn\n","import pytorch_pfn_extras as ppe\n","\n","class Classifier(nn.Module):\n","    \"\"\"two class classfication\"\"\"\n","\n","    def __init__(self, predictor, lossfun=cross_entropy_with_logits):\n","        super().__init__()\n","        self.predictor = predictor\n","        self.lossfun = lossfun\n","        self.prefix = \"\"\n","\n","    def forward(self, image, targets):\n","        outputs = self.predictor(image)\n","        loss = self.lossfun(outputs, targets)\n","        metrics = {\n","            f\"{self.prefix}loss\": loss.item(),\n","            f\"{self.prefix}acc\": accuracy_with_logits(outputs, targets).item()\n","        }\n","        ppe.reporting.report(metrics, self)\n","        return loss, metrics\n","\n","    def predict(self, data_loader):\n","        pred = self.predict_proba(data_loader)\n","        label = torch.argmax(pred, dim=1)\n","        return label\n","\n","    def predict_proba(self, data_loader):\n","        device: torch.device = next(self.parameters()).device\n","        y_list = []\n","        self.eval()\n","        with torch.no_grad():\n","            for batch in data_loader:\n","                if isinstance(batch, (tuple, list)):\n","                    # Assumes first argument is \"image\"\n","                    batch = batch[0].to(device)\n","                else:\n","                    batch = batch.to(device)\n","                y = self.predictor(batch)\n","                y = torch.softmax(y, dim=-1)\n","                y_list.append(y)\n","        pred = torch.cat(y_list)\n","        return pred"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["\"\"\"\n","Referenced `chainer.dataset.DatasetMixin` to work with pytorch Dataset.\n","\"\"\"\n","import numpy\n","import six\n","import torch\n","from torch.utils.data.dataset import Dataset\n","\n","\n","class DatasetMixin(Dataset):\n","\n","    def __init__(self, transform=None):\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        \"\"\"Returns an example or a sequence of examples.\"\"\"\n","        if torch.is_tensor(index):\n","            index = index.tolist()\n","        if isinstance(index, slice):\n","            current, stop, step = index.indices(len(self))\n","            return [self.get_example_wrapper(i) for i in\n","                    six.moves.range(current, stop, step)]\n","        elif isinstance(index, list) or isinstance(index, numpy.ndarray):\n","            return [self.get_example_wrapper(i) for i in index]\n","        else:\n","            return self.get_example_wrapper(index)\n","\n","    def __len__(self):\n","        \"\"\"Returns the number of data points.\"\"\"\n","        raise NotImplementedError\n","\n","    def get_example_wrapper(self, i):\n","        \"\"\"Wrapper of `get_example`, to apply `transform` if necessary\"\"\"\n","        example = self.get_example(i)\n","        if self.transform:\n","            example = self.transform(example)\n","        return example\n","\n","    def get_example(self, i):\n","        \"\"\"Returns the i-th example.\n","\n","        Implementations should override it. It should raise :class:`IndexError`\n","        if the index is invalid.\n","\n","        Args:\n","            i (int): The index of the example.\n","\n","        Returns:\n","            The i-th example.\n","\n","        \"\"\"\n","        raise NotImplementedError"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","\n","class VinbigdataTwoClassDataset(DatasetMixin):\n","    def __init__(self, dataset_dicts, image_transform=None, transform=None, train: bool = True,\n","                 mixup_prob: float = -1.0, label_smoothing: float = 0.0):\n","        super(VinbigdataTwoClassDataset, self).__init__(transform=transform)\n","        self.dataset_dicts = dataset_dicts\n","        self.image_transform = image_transform\n","        self.train = train\n","        self.mixup_prob = mixup_prob\n","        self.label_smoothing = label_smoothing\n","\n","    def _get_single_example(self, i):\n","        d = self.dataset_dicts[i]\n","        filename = d[\"file_name\"]\n","\n","        img = cv2.imread(filename)\n","        if self.image_transform:\n","            img = self.image_transform(img)\n","        img = torch.tensor(np.transpose(img, (2, 0, 1)).astype(np.float32))\n","\n","        if self.train:\n","            label = int(len(d[\"annotations\"]) > 0)  # 0 normal, 1 abnormal\n","            if self.label_smoothing > 0:\n","                if label == 0:\n","                    return img, float(label) + self.label_smoothing\n","                else:\n","                    return img, float(label) - self.label_smoothing\n","            else:\n","                return img, float(label)\n","        else:\n","            # Only return img\n","            return img, None\n","\n","    def get_example(self, i):\n","        img, label = self._get_single_example(i)\n","        if self.mixup_prob > 0. and np.random.uniform() < self.mixup_prob:\n","            j = np.random.randint(0, len(self.dataset_dicts))\n","            p = np.random.uniform()\n","            img2, label2 = self._get_single_example(j)\n","            img = img * p + img2 * (1 - p)\n","            if self.train:\n","                label = label * p + label2 * (1 - p)\n","\n","        if self.train:\n","            label_logit = torch.tensor([1 - label, label], dtype=torch.float32)\n","            return img, label_logit\n","        else:\n","            # Only return img\n","            return img\n","\n","    def __len__(self):\n","        return len(self.dataset_dicts)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def get_vinbigdata_dicts_test(img, width, height):\n","    dataset_dicts = []\n","    record = {}\n","    record[\"file_name\"] = img\n","    # record[\"image_id\"] = index\n","    record[\"image_id\"] = img\n","    record[\"height\"] = height\n","    record[\"width\"] = width\n","    # objs = []\n","    # record[\"annotations\"] = objs\n","    dataset_dicts.append(record)\n","    return dataset_dicts\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def predict_2class(test_img, width, height):\n","    model = build_predictor(model_name=flags.model_name, model_mode=flags.model_mode)\n","    weight_path = 'weights/predictor.pt'\n","    state_dict = torch.load(weight_path)\n","\n","    # Load your weights into the model\n","    model.load_state_dict(state_dict)\n","\n","    classifier = Classifier(model)\n","\n","    dataset_dicts_test = get_vinbigdata_dicts_test(test_img, width, height)\n","    test_dataset = VinbigdataTwoClassDataset(dataset_dicts_test, train=False)\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=flags.valid_batchsize,\n","        num_workers=flags.num_workers,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","    test_pred = classifier.predict_proba(test_loader).cpu().numpy()\n","    test_pred_df = pd.DataFrame({\n","        \"image_id\": [d[\"image_id\"] for d in dataset_dicts_test],\n","        \"class0\": test_pred[:, 0],\n","        \"class1\": test_pred[:, 1]\n","    })\n","    return test_pred_df"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","def filter_2class(test_img, width, height):\n","    low_threshold = 0.0\n","    high_threshold = 0.9\n","\n","    NORMAL = \"14 1 0 0 1 1\"\n","\n","    test_pred_df = predict_2class(test_img, width, height)\n","\n","    p0 = test_pred_df.loc[0, \"class0\"]\n","    if p0 < low_threshold:\n","        print('Keep')\n","        return True\n","    elif low_threshold <= p0 and p0 < high_threshold:\n","        #boxes.append([0, 0, 1, 1])\n","        #scores.append(p0)\n","        #labels.append(14)\n","        print('Add')\n","        return True\n","    else:\n","        # boxes = [[0, 0, 1, 1]]\n","        # scores = [p0]\n","        # labels = [14]\n","        print('Replace')\n","        return False\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Filter Cardiomegaly"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# !python3 cardiomegaly_filter/cardiomegaly_adjusted_776.py --path ./images --threshold 0.52 --low 0.5 --high 0.55"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from cardiomegaly_filter.cardiomegaly_detection import load_models, predict\n","import torch\n","global device, unet, unet2\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","unet, unet2 = load_models(device)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["import csv\n","import pandas as pd\n","import math\n","\n","#INPUT_PATH = 'submission_ensemble.csv'\n","#INPUT_PATH = 'subm_folder/yolo_filter_25_001.csv'\n","#OUTPUT_PATH = 'yolo_filter_25_001_final.csv'\n","CARDIO_CLASS = 3\n","NO_FINDINGS_CLASS = 14\n","CARDIO_PATH = 'result/'\n","THRESHOLD_NO_FINDINGS = 0.98\n","\n","global cnt\n","cnt = 0\n","\n","def find_best_score(preds):\n","    if len(preds) == 0:\n","        return []\n","    \n","    res = preds[0]\n","    for class_id, score, location in preds:\n","        if score > res[1]:\n","            res = (class_id, score, location)\n","    \n","    return [res]\n","        \n","def is_cardiomegaly(filename, pred, preds):\n","    numbers = []\n","    with open(CARDIO_PATH + filename + '.txt', 'r') as file:\n","        for line in file:\n","            # Split the line into individual elements\n","            elements = line.strip().split()\n","            for element in elements:\n","                try:\n","                    number = float(element)\n","                    numbers.append(number)\n","                except ValueError:\n","                    pass\n","\n","    class_id = numbers[0]\n","    score = numbers[1]\n","    location = numbers[2:6]\n","    \n","    flag1 = class_id == CARDIO_CLASS\n","    flag2 = len(pred) > 0\n","   \n","    if flag2:\n","        if not flag1 and score > 0.6:\n","            best = find_best_score(pred)[0]\n","            if best[1] <= 0.3:\n","                return preds\n","            else:\n","                return preds + pred\n","        elif flag1 and score > 0.6:\n","            best = find_best_score(pred)[0]\n","            preds.append((best[0], best[1] * 2, best[2]))\n","            return preds\n","        else:\n","            return preds + pred\n","    else:\n","        return preds + pred\n","\n","\n","def filter_cardiomegaly(labels, scores, boxes, width, height):\n","    filename = 'test'\n","\n","    cardios = []\n","    no_findings = []\n","    preds = []\n","\n","    for i, label in enumerate(labels):\n","        score = scores[i]\n","        box = boxes[i]\n","        \n","        if label == CARDIO_CLASS:\n","            cardios.append((label, score, box))\n","        else:\n","            preds.append((label, score, box))\n","\n","        if label == NO_FINDINGS_CLASS:\n","            no_findings.append((label, score, box))\n","\n","    # if out_row[0] != '1' or out_row[1] != '4':\n","    #     pred, difference = is_cardiomegaly(filename, cardios)\n","    #     out_row = f'{out_row}{convert2string(pred)}'\n","    #if len(no_findings) == 0 or find_best_score(no_findings)[0][1] < THRESHOLD_NO_FINDINGS:\n","    new_preds = is_cardiomegaly(filename, cardios, preds)\n","    final_preds = []\n","    for pred in new_preds:\n","        label, score, box = pred\n","        if score >= 0.1:\n","            final_preds.append((label, score, [box[0] * width, box[1] * height, box[2] * width, box[3] * height]))\n","\n","    return final_preds"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["def predict_image(test_img, file_name):\n","    global image\n","    image = Image.open(test_img)\n","    width, height = image.size\n","\n","    preds = run_yolo_5fold(test_img, width, height)\n","    best_iou = 0.3\n","    boxes, scores, labels = ensemble(preds, [1, 1, 1, 1, 1], best_iou, w=width, h=height)\n","\n","    if not filter_2class(test_img, width, height):\n","        boxes = [[0, 0, 1, 1]]\n","        scores = [1]\n","        labels = [14]\n","\n","    #!python3 cardiomegaly_filter/cardiomegaly_adjusted_776.py --path ./images --threshold 0.52 --low 0.5 --high 0.55\n","    global unet, unet2, device\n","    print(\"Predict Cardio\")\n","    predict(unet, unet2, device, file_name)\n","\n","    print(\"Filter Cardio\")\n","    final_preds = filter_cardiomegaly(labels, scores, boxes, width, height)\n","\n","    return visualize_yolo(test_img, final_preds, width, height)\n","    \n","    "]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://localhost:8080\n","\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["demo.jpg\n","Save =  images/test.jpg\n","Yolo 5 fold running!\n","Ensemble 5 folds!\n","Add\n","Predict Cardio\n"]},{"name":"stderr","output_type":"stream","text":["127.0.0.1 - - [13/Jun/2023 01:44:35] \"POST / HTTP/1.1\" 200 -\n","127.0.0.1 - - [13/Jun/2023 01:44:35] \"GET /static/test.jpg?0.05658256496780578 HTTP/1.1\" 200 -\n","127.0.0.1 - - [13/Jun/2023 01:44:35] \"\u001b[36mGET /static/bg.jpg HTTP/1.1\u001b[0m\" 304 -\n"]},{"name":"stdout","output_type":"stream","text":["No Heart Segment!\n","Filter Cardio\n","Draw boxes!\n"]}],"source":["import pickle\n","from flask import Flask, render_template, request\n","from werkzeug.wrappers import Request, Response\n","import dlib\n","import os\n","from random import random\n","import cv2\n","import numpy as np\n","import  sys\n","\n","\n","# Kh·ªüi t·∫°o Flask\n","app = Flask(__name__)\n","app.config['UPLOAD_FOLDER'] = \"static\"\n","\n","# H√†m x·ª≠ l√Ω request\n","@app.route(\"/\", methods=['GET', 'POST'])\n","def home_page():\n","    # N·∫øu l√† POST (g·ª≠i file)\n","    if request.method == \"POST\":\n","         try:\n","            # L·∫•y file g·ª≠i l√™n\n","            image = request.files['file']\n","            if image:\n","                # L∆∞u file\n","                print(image.filename)\n","                filename = 'test.' + image.filename.split('.')[-1]\n","                path_to_save = 'images/' + filename\n","                print(\"Save = \", path_to_save)\n","                image.save(path_to_save)\n","\n","                global test_img\n","                test_img = path_to_save\n","\n","                pred_image = predict_image(path_to_save, filename)\n","\n","                out_path = app.config['UPLOAD_FOLDER'] + \"/\" + filename\n","                cv2.imwrite(out_path, pred_image)\n","\n","                    # Tr·∫£ v·ªÅ k·∫øt qu·∫£\n","                return render_template(\"index.html\", user_image = filename , rand = str(random()), \n","                                       msg=\"Uploaded successfully!\")\n","            else:\n","                # N·∫øu kh√¥ng c√≥ file th√¨ y√™u c·∫ßu t·∫£i file\n","                return render_template('index.html', msg='Choose file.')\n","\n","         except Exception as ex:\n","            # N·∫øu l·ªói th√¨ th√¥ng b√°o\n","            print(ex)\n","            return render_template('index.html', msg='Something wrong!')\n","\n","    else:\n","        # N·∫øu l√† GET th√¨ hi·ªÉn th·ªã giao di·ªán upload\n","        return render_template('index.html')\n","\n","\n","if __name__ == '__main__':\n","    #app.run(host='127.0.0.1', debug=True)\n","    from werkzeug.serving import run_simple\n","    run_simple('localhost', 8080, app)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"papermill":{"duration":7088.304633,"end_time":"2021-04-06T17:43:04.135904","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-04-06T15:44:55.831271","version":"2.1.0"}},"nbformat":4,"nbformat_minor":0}
